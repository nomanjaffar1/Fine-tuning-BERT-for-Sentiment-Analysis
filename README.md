# Fine-tuning-BERT-for-Sentiment-Analysis
<br>
This repository focuses on fine-tuning a pre-trained BERT (Bidirectional Encoder Representations from Transformers) model for sentiment analysis using the Twitter Sentiment Data Analysis dataset. The primary objective is to modify the last layer of BERT to predict sentiment across four or more classes and evaluate its performance on a held-out test set. The tasks include data pre-processing, where the dataset is split into validation and test sets, model adaptation using Hugging Face's Transformers library to load and modify BERT, and training the model with a focus on updating the classification layer while keeping the BERT base frozen. After training, the model is evaluated using standard metrics like accuracy, precision, recall, and F1-score to assess its effectiveness in sentiment classification. The repository includes scripts for data pre-processing, model training, and evaluation, providing a streamlined workflow for fine-tuning BERT on multi-class sentiment analysis tasks. Detailed results and analysis are presented in a project report to interpret the model's performance and provide insights into its efficacy for sentiment analysis.